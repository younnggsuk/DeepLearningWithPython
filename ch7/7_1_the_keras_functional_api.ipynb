{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 Sequential 모델을 넘어서: 케라스의 함수형 API\n",
    "\n",
    "### `Sequential` 모델\n",
    "\n",
    "- `Sequential` 모델은 네트워크의 입력과 출력이 하나\n",
    "- 많은 경우에 이 모델이 적절하지만 `Sequential` 모델로 구현하지 못하는 경우도 있음\n",
    "    - 다중 입력 모델\n",
    "    - 다중 출력 모델\n",
    "    - 비순환 유향 그래프 같은 네트워크 구조들\n",
    "\n",
    "\n",
    "<img src=\"./images/sequential_model.jpeg\" alt=\"sequential_model\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 다중 입력 모델\n",
    "\n",
    "- 다양한 입력 소스에서 전달된 데이터를 각각 다른 종류의 신경망으로 처리하고 합치는 형태\n",
    "\n",
    "- 예) 중고 의류의 시장 가격 예측\n",
    "    - 입력 : 메타데이터(의류브랜드, 연도 등), 사용자가 제공한 텍스트 설명, 제품 사진\n",
    "    - 신경망 : FCN, RNN, CNN\n",
    "    - 출력 : 가격\n",
    "    \n",
    "    \n",
    "<img src=\"./images/multi_input_model.png\" alt=\"multi_input_model\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 다중 출력 모델\n",
    "\n",
    "- 입력 데이터에서 여러개의 target 속성을 예측하는 경우\n",
    "\n",
    "- 예) 소설이나 짧은 글의 장르 및 시대 예측\n",
    "    - 입력 : 소설 텍스트\n",
    "    - 신경망 : 분류 모델, 회귀 모델\n",
    "    - 출력 : 장르, 시대\n",
    "    \n",
    "\n",
    "<img src=\"./images/multi_output_model.png\" alt=\"multi_output_model\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 비순환 유향 그래프 형태의 모델\n",
    "\n",
    "- 최근에 개발된 많은 신경망 구조는 비순환 유향 그래프 형태를 가짐\n",
    "\n",
    "####  inception module을 사용한 Inception 계열의 네트워크\n",
    "\n",
    "- 입력을 나란히 놓인 여러개의 CNN을 통과시킨 후 하나의 텐서로 합침\n",
    "\n",
    "\n",
    "<img src=\"./images/inception_module.png\" alt=\"inception_module\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### residual connection을 이용한 ResNet 계열의 네트워크\n",
    "\n",
    "- 하위 층의 출력 텐서를 상위 층의 출력 텐서에 더함\n",
    "- 하위층에서 학습된 정보가 데이터 처리 과정에서 손실되는 것을 방지\n",
    "\n",
    "\n",
    "<img src=\"./images/residual_connection.png\" alt=\"residual_connection\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 함수형 API 소개\n",
    "\n",
    "### 함수형 API\n",
    "\n",
    "- 함수형 API(functional API)는 함수처럼 층을 사용하며 직접 텐서들의 입출력을 다룸\n",
    "\n",
    "- 케라스의 `Model` 클래스를 통해 구현\n",
    "\n",
    "#### `Model` 클래스\n",
    "\n",
    "- 입력 텐서(`input_tensor`)와 출력 텐서(`output_tensor`)를 받음\n",
    "- 입력 텐서에서 출력 텐서로 가는데 필요한 모든 층을 추출\n",
    "- 추출한 모든 층을 모아서 그래프 데이터 구조인 `Model` 객체를 생성\n",
    "\n",
    "\n",
    "- 관련되지 않은 입력과 출력으로 모델을 만들면 `RuntimeError` 발생\n",
    "\n",
    "\n",
    "### Sequential 모델과 함수형 API의 비교 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential 모델\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers\n",
    "\n",
    "seq_model = Sequential()\n",
    "\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "seq_model.summary()\n",
    "\n",
    "# compile()이후 단계는 동일함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Functional API\n",
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "func_model = Model(input_tensor, output_tensor)\n",
    "\n",
    "func_model.summary()\n",
    "\n",
    "# compile()이후 단계는 동일함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.2 다중 입력 모델\n",
    "\n",
    "### 다중 입력 모델\n",
    "\n",
    "- Functional API를 사용하면 다중 입력 모델을 만들 수 있음\n",
    "- 서로 다른 입력을 합치기 위해 텐서를 연결하는 층을 사용함\n",
    "    - `keras.layers.Add()`, `keras.layers.Concatenate()` 등\n",
    "    - 위의 2가지 외에도 여러가지 함수들이 있음(케라스의 Merge layer 참고)\n",
    "    \n",
    "### 다중 입력 모델 예제 : 질문-응답 모델\n",
    "\n",
    "- 입력 : 자연어 질문, 답변에 필요한 정보가 담긴 텍스트(뉴스기사 등)\n",
    "- 신경망 : LSTM, LSTM\n",
    "- 출력 : 단어로 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           12416       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 16)           3136        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 48)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 500)          24500       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Functional API로 질문-응답 모델 구현\n",
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "text_voca_size = 10000\n",
    "question_voca_size = 10000\n",
    "\n",
    "answer_voca_size = 500\n",
    "\n",
    "\n",
    "# 1. 정보 텍스트\n",
    "\n",
    "# shape=(None,) : 입력 텍스트의 길이가 정해지지 않음\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = Embedding(text_voca_size, 64)(text_input)\n",
    "encoded_text = LSTM(32)(embedded_text)\n",
    "\n",
    "# 2. 자연어 질문\n",
    "\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = Embedding(question_voca_size, 32)(question_input)\n",
    "encoded_question = LSTM(16)(embedded_question)\n",
    "\n",
    "# 1과 2의 출력을 하나로 합침\n",
    "\n",
    "# axis 매개변수는 -1이 기본값이므로 생략해도 됨\n",
    "concatenated = Concatenate(axis=-1)([encoded_text, encoded_question])\n",
    "\n",
    "answer = Dense(answer_voca_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n",
      "(1000, 100)\n",
      "(1000, 500)\n"
     ]
    }
   ],
   "source": [
    "# 구현을 위해 난수로 데이터 생성\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "# 데이터 생성\n",
    "text = np.random.randint(1, text_voca_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_voca_size, size=(num_samples, max_length))\n",
    "answers = np.random.randint(0, answer_voca_size, size=num_samples)\n",
    "\n",
    "\n",
    "# ont-hot encoding\n",
    "answers = to_categorical(answers)\n",
    "\n",
    "print(text.shape)\n",
    "print(question.shape)\n",
    "print(answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 6.2146 - acc: 0.0010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 6.1943 - acc: 0.0200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 6.1191 - acc: 0.0060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 6.0409 - acc: 0.0060\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.9839 - acc: 0.0070\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.9122 - acc: 0.0110\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.8339 - acc: 0.0160\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.7333 - acc: 0.0150\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 5.6616 - acc: 0.0280\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.5762 - acc: 0.0330\n",
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 5.5104 - acc: 0.0310\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.4440 - acc: 0.0500\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.3870 - acc: 0.0610\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 5.3282 - acc: 0.0450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.2810 - acc: 0.0680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.1839 - acc: 0.0800\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.1354 - acc: 0.0860\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 5.0610 - acc: 0.0880\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0073 - acc: 0.1030\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 4.9504 - acc: 0.1160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc2085fd6d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 시키기\n",
    "\n",
    "model.compile(optimizer=RMSprop(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# 방법 1. 리스트로 주입\n",
    "model.fit([text, question], answers,\n",
    "          epochs=10, batch_size=128)\n",
    "\n",
    "# 방법 2. Input 클래스의 name 매개변수로 전달한 이름으로 딕셔너리 만들어서 전달\n",
    "model.fit({'text':text, 'question':question}, answers,\n",
    "          epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.3 다중 출력 모델\n",
    "\n",
    "### 다중 출력 모델\n",
    "\n",
    "- Functional API를 사용하면 다중 출력 모델을 만들 수 있음\n",
    "- 서로 다른 출력별로 각각 서로 다른 손실함수를 지정하고 손실값을 하나로 합쳐서 경사하강법을 적용\n",
    "    - 경사 하강법은 하나의 스칼라 값을 최소화 하므로 손실 값을 하나로 합침\n",
    "    \n",
    "\n",
    "#### 손실 값의 불균형\n",
    "- 서로 다른 손실 값이 불균형하면 개별 손실 값이 큰 작업에 치우쳐서 학습되므로 다른 작업들이 손해를 입음\n",
    "- 이를 해결하기 위해 각 손실 값별로 전체 손실에 기여하는 수준(가중치)을 적용할 수 있음\n",
    "    - `compile()`의 `loss_weights` 매개변수에 리스트로 전달\n",
    "    \n",
    "    \n",
    "- 서로 다른 2개의 loss를 가지는 경우의 예\n",
    "    - loss1\n",
    "        - 일반적으로 3~5 값을 가짐\n",
    "        - 가중치를 0.25로 줌\n",
    "        - loss1*0.25 = 0.75~1.25\n",
    "    - loss2\n",
    "        - 일반적으로 0.1정도의 값을 가짐\n",
    "        - 가중치를 10으로 줌\n",
    "        - loss2*10 = 1\n",
    "    \n",
    "    \n",
    "### 다중 출력 모델 예제 : sns의 포스트를 통한 나이, 성별, 소득수준 예측 문제\n",
    "\n",
    "- 입력 : sns의 포스트(텍스트)\n",
    "- 신경망 : 1D CNN\n",
    "- 출력 : 회귀, 다중분류, 이진분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 128)    163968      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 128)    0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 256)    164096      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 256)    327936      conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, None, 256)    0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 256)    327936      max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 256)    327936      conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 2)            258         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,146,445\n",
      "Trainable params: 14,146,445\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "voca_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "\n",
    "embedding_posts = Embedding(voca_size, 256)(posts_input)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu')(embedding_posts)\n",
    "x = MaxPooling1D(5)(x)\n",
    "\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = Dense(1, name='age')(x)\n",
    "gender_prediction = Dense(2, name='gender', activation='sigmoid')(x)\n",
    "income_prediction = Dense(num_income_groups, name='income', activation='softmax')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, gender_prediction, income_prediction])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 학습시키기\n",
    "\n",
    "# train, target 데이터가 만들어져있다고 가정\n",
    "\n",
    "# 각 loss가 아래와 같이 나온다고 가정\n",
    "# mse loss : 3~5,\n",
    "# binary crossentropy loss : 0.1\n",
    "# categorical crossentropy loss : 1\n",
    "\n",
    "# 방법 1 : 순서대로 리스트로 넣기\n",
    "\n",
    "model.compile(optimizer=RMSprop,\n",
    "              loss=['mse', 'binary_crossentropy', 'categorical_crossentropy'],\n",
    "              loss_weights=[0.25, 10., 1.])\n",
    "\n",
    "model.fit(posts, [age_targets, gender_targets, income_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "\n",
    "\n",
    "# 방법 2 : 이름 지정해서 넣기\n",
    "\n",
    "model.compile(optimizer=RMSprop,\n",
    "              loss={'age':'mse',\n",
    "                    'gender':'binary_crossentropy',\n",
    "                    'income':'categorical_crossentropy'},\n",
    "              loss_weights={'age':0.25,\n",
    "                            'gender':10.,\n",
    "                            'income':1.})\n",
    "\n",
    "model.fit(posts, {'age': age_targets,\n",
    "                  'gender': gender_targets,\n",
    "                  'income': income_targets},\n",
    "          epochs=10, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
