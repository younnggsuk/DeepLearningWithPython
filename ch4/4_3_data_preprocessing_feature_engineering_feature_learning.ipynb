{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 데이터 전처리, 특성 공학, 특성 학습\n",
    "\n",
    "- 데이터 전처리 및 특성 공학 기법은 특성 도메인에 종속적임\n",
    "    - 예) 텍스트 데이터나 이미지 데이터에 특화된 기법들\n",
    "- 이 장에서는 모든 데이터에 공통되는 기본 사항들을 다룸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 신경망을 위한 데이터 전처리\n",
    "\n",
    "- 데이터 전처리 목적은 **원본 데이터를 신경망에 적용하기 쉽도록 만드는 것**\n",
    "- 벡터화(vectorization), 정규화(normalization), 누락된 값 다루기, 특성 추출 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 벡터화 (Vectorization)\n",
    "- 신경망에서 **모든 입력과 타깃은 부동 소수 데이터로 이루어진 텐서**여야 함\n",
    "- 사운드, 이미지, 텍스트 등 처리해야 할 것이 무엇이든 먼저 텐서로 변환해야 하는데, 이를 데이터 벡터화라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 값 정규화 (Normalization)\n",
    "\n",
    "- **비교적 큰 값이나 균일하지 않은 데이터를 신경망에 주입하는 것은 위험**함\n",
    "    - 네트워크 가중치 초기값 보다 훨씬 큰 여러 자릿수를 가진 정수 데이터(큰 값의 예)\n",
    "    - 한 특성의 범위는 0\\~1, 다른 특성은 100\\~200인 데이터(균일하지 않은 예)    \n",
    "- 이러한 경우, 업데이트 할 그래디언트가 커져 네트워크의 수렴을 방해함\n",
    "\n",
    "\n",
    "- 네트워크를 쉽게 학습시키기 위해서는 데이터가 다음과 같은 특징을 따라야 함\n",
    "    - **작은 값**을 취해야 함(일반적으로 0\\~1 사이)\n",
    "    - **균일**해야 함(모든 특성이 비슷한 범위를 가져야 함)\n",
    "    \n",
    "    \n",
    "- 추가로 z-transformation(표준정규분포 형태로 만드는 것)과 같은 방법은 자주 사용됨\n",
    "    - 각 특성별로 평균이 0, 표준편차가 1이 되도록 정규화 하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 누락된 값 다루기 (Handling missing values)\n",
    "\n",
    "- 누락된 값이란 **데이터셋에 특정 값이 누락된 경우**를 말함\n",
    "    - 예) 주택 가격 데이터 셋에서 첫번째 특성(1인당 범죄율)이 모든 샘플에 들어가 있지 않은 경우\n",
    "- **누락된 값이 없는 데이터에서 훈련된 모델(네트워크)는 누락된 값을 무시하거나 다루는 방법을 알지 못하므로 문제가 됨**\n",
    "\n",
    "\n",
    "- 누락된 값을 처리하는 방법들\n",
    "    - 누락된 값을 0으로 해서 **무의미 하다는 의미로 학습시켜 이 값을 무시하도록** 학습시키기(이 경우, 누락된 값이 있는 훈련 샘플을 고의로 만들어야 함)\n",
    "    - 누락된 값이 있는 **훈련 샘플을 제외**시키기\n",
    "    - 누락된 값이 있는 특성이 덜 중요하다고 판단되면 해당 **특성을 모두 제외**시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 특성 공학 (Feature Engineering)\n",
    "\n",
    "- 특성공학은 데이터와 머신러닝 알고리즘(신경망)에 관한 지식을 사용하는 단계\n",
    "- 모델에 데이터를 주입하기 전에 하드코딩된 변환을 적용해 알고리즘이 더 잘 수행되도록 만들어 주는 것\n",
    "- **모델이 잘 학습되도록 데이터를 다른 방식으로 표현하는 것**\n",
    "\n",
    "\n",
    "- 예) 시계의 시간을 읽기 위한 특성 공학\n",
    "    - 2차원 픽셀 시계 이미지 데이터를 시계 바늘의 각도 $\\theta$로 나타내는 것\n",
    "    - 훨씬 더 학습하기 좋은 특성으로 표현함으로써 학습이 더 잘됨\n",
    "    \n",
    "\n",
    "- 특성 공학을 위해서는 일반적으로 **해당 문제를 아주 잘 이해하고 있어야 함**\n",
    "\n",
    "\n",
    "- **딥러닝 이전**(전통적인 얕은 학습)에는 **특성 공학이 중요**했음\n",
    "    - 스스로 유용한 특성을 학습할 만큼 충분히 넓은 가설 공간을 가지고 있지 않았음\n",
    "- **딥러닝 이후**에는 **대부분 특성공학이 필요하지 않음**\n",
    "    - 신경망이 자동으로 원본 데이터에서 유용한 특성을 추출할 수 있기 때문\n",
    "    \n",
    "    \n",
    "- **하지만 딥러닝에서도 특성 공학을 신경써야 함**\n",
    "    - 좋은 특성은 **적은 자원**을 사용하여 문제를 풀 수 있음\n",
    "    - 좋은 특성은 **적은 데이터**로 문제를 풀 수 있음(딥러닝 모델이 스스로 특성을 학습하는 능력은 데이터가 많을 때 발휘됨)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
