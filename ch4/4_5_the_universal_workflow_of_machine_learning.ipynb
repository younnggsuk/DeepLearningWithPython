{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 보편적인 머신러닝 작업 흐름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.1 문제 정의와 데이터셋 수집\n",
    "\n",
    "### 문제 정의\n",
    "- **입력 데이터**가 무엇인지? **어떤 것을 예측**하려고 하는지?\n",
    "    - 보통 가용 데이터의 유무가 이 단계에서의 제한요소가 됨\n",
    "    \n",
    "    \n",
    "- **문제의 종류**가 어떤 것인지?\n",
    "    - 이진 분류?\n",
    "    - 다중 분류?\n",
    "    - 스칼라 회귀?\n",
    "    - 벡터 회귀?\n",
    "    - 다중 레이블 다중 분류?\n",
    "    - 그 외의 다른 문제(군집, 생성, 강화학습 등)?\n",
    "    \n",
    "### 가설 세우기\n",
    "- **주어진 입력으로 출력을 예측할 수 있다**고 가설을 세움\n",
    "- **가용한 데이터에 입력과 출력 사이의 관계를 학습하는데 충분한 정보가 있다**고 가설을 세움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.2 성공 지표 선택\n",
    "\n",
    "### 성공 지표\n",
    "\n",
    "- **성공의 지표가** 모델이 최적화할 **손실함수를 선택하는 기준**이 됨(그렇다고 **성공의 지표가 손실 함수는 아님**)\n",
    "    - 정확도(Accuracy)?\n",
    "    - 정밀도(Precision)?\n",
    "    - 재현율(Recall)?\n",
    "    \n",
    "    \n",
    "- **클래스 분포가 균일한 분류 문제**에서는 **정확도와 ROC AUC**가 일반적인 지표\n",
    "- **클래스 분포가 균일하지 않은(Object detection과 같이 클래스가 있을 수도 있고 없을 수도 있는) 분류 문제**에서는 **정밀도(Precision)와 재현율(Recall)**을 사용할 수 있음\n",
    "- **랭킹 문제나 다중 레이블 문제**는 **평균정밀도**를 사용할 수 있음\n",
    "\n",
    "**[모델 성공 평가 지표에 대한 자세한 설명](#모델-성공-평가-지표)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.3 평가 방법 선택\n",
    "\n",
    "### 주로 사용되는 3가지의 평가 방식\n",
    "- **홀드아웃 검증 세트 분리**\n",
    "    - **데이터가 풍부**할 경우\n",
    "    \n",
    "    \n",
    "- **K-겹 교차 검증**\n",
    "    - 홀드아웃 검증을 사용하기에 **샘플 수가 너무 적을 때**\n",
    "\n",
    "      \n",
    "- **반복 K-겹 교차 검증**\n",
    "    - **데이터가 적고 매우 정확한 모델 평가가 필요할 때**\n",
    "  \n",
    "\n",
    "- 3가지 방식 중 어떤 것을 선택?\n",
    "    - **딥러닝 모델**을 사용할 경우 데이터가 풍부한 상황이므로 **주로 홀드아웃 검증 세트 분리**를 사용 \n",
    "    - **교차 검증은 얕은 학습**에서 자주 사용됨\n",
    "    - 딥러닝 모델은 훈련 비용이 너무 커서 교차 검증을 적용하기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.4 데이터 준비\n",
    "\n",
    "### 머신러닝 모델에 주입할 데이터를 구성\n",
    "\n",
    "- **데이터를 텐서로** 재구성\n",
    "\n",
    "\n",
    "- 텐서의 값을 **작은 값의 스케일로 조정** ( [-1, 1]범위 또는 [0, 1] )\n",
    "    - Ex) 0~1 범위로 조정 ( x = (x-xmin) / (xmax-xmin) )\n",
    "    \n",
    "    \n",
    "- 특성마다 범위가 다르면 **정규화(standardization)**\n",
    "    - Ex) z-transformation 적용 ( x = (x - mean) / (std) )\n",
    "    \n",
    "    \n",
    "- **특성 공학(Feature Engineering)** 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.5 기본보다 나은 모델 훈련하기\n",
    "\n",
    "### 통계적 검정력(statistical power)을 달성\n",
    "\n",
    "- 아주 단순한 모델보다 나은 수준(**random classifier보다 좋은 성능**)의 작은 모델을 개발\n",
    "    - MNIST의 경우 10개의 클래스이므로 0.1보다 높은 정확도를 내는 모델\n",
    "    - IMDB의 경우 binary classification이므로 0.5보다 높은 정확도를 내는 모델\n",
    "  \n",
    "\n",
    "- **통계적 검정력을 달성**한다는 것은 **가설을 검증**한다는 의미\n",
    "    - 검증해야 할 2가지 가설\n",
    "        1. 준비한 데이터 입력으로 출력을 예측할 수 있다.\n",
    "        2. 가용한 데이터에 입력과 출력 사이의 관계를 학습하는데 충분한 정보가 있다.\n",
    "    - **가설 검증이 되지 않을 경우 기획부터 다시 해야 함**\n",
    "\n",
    "\n",
    "### 첫 번째 모델을 만들기 위한 3가지 중요한 선택(가설 검증이 되었을 경우)\n",
    "\n",
    "1. **마지막 층의 활성화 함수(Activation)**\n",
    "    - classification의 주로 sigmoid(binary) or softmax(multi-class)\n",
    "    - regression의 경우 주로 활성화 함수 사용 X (linear)\n",
    "\n",
    "\n",
    "2. **손실 함수(Loss)**\n",
    "    - classfication의 경우 주로 crossentropy\n",
    "    - regression의 경우 주로 mse(mean squared error)\n",
    "   \n",
    "\n",
    "3. **최적화 설정(Optimizer)**\n",
    "    - 대부분의 경우 rmsprop과 기본 learning rate를 사용하는 것이 무난함\n",
    "    - rmsprop, adam의 경우 기본 lr=0.001\n",
    "    - sgd, adagrad의 경우 기본 lr=0.01\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    "    <thead >\n",
    "        <tr >\n",
    "            <th style=\"text-align:center\" >문제 유형</th>\n",
    "            <th style=\"text-align:center\">마지막 층의 활성화 함수</th>\n",
    "            <th style=\"text-align:center\">손실 함수</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"text-align:center\">이진 분류</td>\n",
    "            <td style=\"text-align:center\">sigmoid</td>\n",
    "            <td style=\"text-align:center\">binary_crossentropy</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align:center\">단일 레이블 다중 분류</td>\n",
    "            <td style=\"text-align:center\">softmax</td>\n",
    "            <td style=\"text-align:center\">categorical_crossentropy</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align:center\">다중 레이블 다중 분류</td>\n",
    "            <td style=\"text-align:center\">sigmoid</td>\n",
    "            <td style=\"text-align:center\">binary_crossentropy</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align:center\">임의 값에 대한 회귀</td>\n",
    "            <td style=\"text-align:center\">없음</td>\n",
    "            <td style=\"text-align:center\">mse</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align:center\">0과 1사이 값에 대한 회귀</td>\n",
    "            <td style=\"text-align:center\">sigmoid</td>\n",
    "            <td style=\"text-align:center\">mse or binary_crossentropy</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "      \n",
    "- 추가) 손실 함수의 선택 시 알아야 할 것(성공지표와의 관계)\n",
    "    - **손실 함수 $\\neq$ 성공 지표**\n",
    "    - 성공 지표를 직접 최적화 하는 것이 항상 가능하지는 않음(**성공 지표를 손실 함수로 바꿀 수 없는 경우가 있음**)\n",
    "    - 손실 함수의 조건\n",
    "        - mini-batch(이론적으로는 하나의 데이터 샘플)에서 계산 가능해야 함\n",
    "        - 미분 가능해야 함\n",
    "    - Ex)\n",
    "        - 분류 지표인 ROC AUC는 직접 최적화 될 수 없으므로 crossentropy를 대신 최적화함 \n",
    "        - 일반적으로 crossentropy가 낮을수록 ROC AUC가 높다고 기대할 수 있음\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.6 몸집 키우기 : 과대적합 모델 구축\n",
    "\n",
    "### 얼마나 큰 모델을 만들 것인가?\n",
    "- underfitting과 overfitting의 경계 사이에 위치한 **이상적인 학습 모델**을 만들어야 하며 그 **경계를 알기 위해** 먼저 **Overfitting되는 모델을 만들어야 함**\n",
    "\n",
    "\n",
    "- Overfitting 모델 만들기\n",
    "    - 층을 추가\n",
    "    - 층의 크기를 키움\n",
    "    - 더 많은 epoch로 훈련\n",
    "\n",
    "\n",
    "- **위의 과정을 수행하며 validation 모델 성능이 감소하기 시작했을 때가 overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.7 모델 규제와 하이퍼파라미터 튜닝\n",
    "\n",
    "- 좋은 모델을 얻을 때 까지 반복적으로 모델을 수정, 훈련, 검증데이터로 평가\n",
    "- 절대 test 데이터 사용 X\n",
    "\n",
    "\n",
    "- 이 단계에서 적용해 볼 사항들\n",
    "    - **Dropout** 추가\n",
    "    - **다른 구조의 network**를 시도\n",
    "        - 층 추가 및 제거\n",
    "    - **L1 or L2 or L1,L2 Regularization** 추가\n",
    "    - **하이퍼파라미터 조정**\n",
    "        - 층의 유닛 수\n",
    "        - optimizer, learning rate\n",
    "    - 선택적으로 **feature engineering**\n",
    "        - 새로운 feature를 추가\n",
    "        - 유용하지 않을 것 같은 feature를 제거\n",
    "\n",
    "\n",
    "- 유념해야 할 사항\n",
    "    - **검증 과정에서** 얻은 피드백을 통해 **모델을 튜닝 할 때마다 검증 과정에 대한 정보를 모델에 누설**하고 있음\n",
    "    - 따라서 **많이 반복하게 되면** 결국 모델이 **검증 데이터에 overfitting**되며 이는 **검증 과정의 신뢰도를 감소**시킴\n",
    "    \n",
    "    \n",
    "- **좋은 성능의 모델 설정을 얻었다면 train+val 데이터로 최종 모델을 학습 후 마지막에 딱 1번 test set에서 평가**\n",
    "\n",
    "\n",
    "- **test set의 성능이 validatin set의 성능 보다 많이 나쁠 경우**\n",
    "    - 검증 과정에서 overfitting되어 **검증의 신뢰도가 없어짐**\n",
    "    - 신뢰도가 높은 **다른 평가 방법으로 바꾸는 것이 좋음**(반복 K-겹 교차 검증)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 과정 요약\n",
    "\n",
    "1. **주어진 문제와 훈련할 데이터를 정의**\n",
    "\n",
    "\n",
    "2. **성공을 어떻게 측정할 지 선택**\n",
    "\n",
    "\n",
    "3. **평가 방법 결정**\n",
    "\n",
    "\n",
    "4. **통계적 검정력이 있는 첫번째 모델 만들기**\n",
    "\n",
    "\n",
    "5. **Overfitting된 모델 만들기**\n",
    "\n",
    "\n",
    "6. **검증 데이터의 성능에 기초해 모델에 규제를 적용하고 하이퍼파라미터를 튜닝**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 성공 평가 지표\n",
    "\n",
    "**TP(True Positive), FP(False Positive), FN(False Negative), TN(True Negative)**\n",
    "\n",
    "<img src=\"./images/TP_FP_FN_TN_table.jpeg\" alt=\"TP_FP_FN_TN_table\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **정확도(Accuracy)**\n",
    "    - **전체 데이터 중 제대로 분류된 데이터 비율(모델의 예측이 얼마나 정확한가)**\n",
    "    - $Accuracy = \\frac{TP + TN}{TP + FP + FN + TN}$\n",
    "\n",
    "\n",
    "- **정밀도(Precision)**\n",
    "    - **양성으로 예측**된 사례 중 **실제로 양성**이었던 사례의 비율\n",
    "    - 예측한 결과가 얼마나 정확한지 즉, **예측 결과 중 정답이 얼마나 있는지**\n",
    "    - 인식/탐지 문제의 성능 판단에서는 **검출된 결과가 얼마나 정확한지 즉, 검출 결과들 중 실제 물체가 얼마나 포함되어있는지**\n",
    "    - $Precision = \\frac{TP}{TP + FP}$\n",
    "    \n",
    "    \n",
    "- **재현율(Sensitivity, TPR(True Positive Rate))**\n",
    "    - **실제 양성** 중 **정확히 양성**이라고 식별된 사례의 비율\n",
    "    - **예측하고자 하는 대상들이 얼마나 예측되었는지**\n",
    "    - 인식/탐지 문제의 성능 판단에서는 **대상 물체들을 얼마나 빠뜨리지 않고 잘 잡아내는지**\n",
    "    - $Recall = \\frac{TP}{TP + FN}$\n",
    "    \n",
    "<br/>\n",
    "\n",
    "**ROC와 AUC**\n",
    "\n",
    "- **ROC(Receiver Operating Characteristic, 수신자 조작 특성)**\n",
    "    - **거짓양성비율(FPR)에 대한 재현율(TPR)의 곡선**을 뜻함\n",
    "        - **TPR(True Positive Rate)**\n",
    "            - $TPR = \\frac{TP}{TP + FN}$\n",
    "            - ROC의 y축 값\n",
    "            - 재현율(Recall)과 같음\n",
    "            \n",
    "        - **FPR(False Positive Rate)**\n",
    "            - $FPR = \\frac{FP}{FP + TN}$\n",
    "            - ROC의 x축 값\n",
    "            \n",
    "    - TRP=1, FPR=0인 (0,1)지점이 가장 이상적임(Perfect Classification)\n",
    "    \n",
    "    \n",
    "- **AUC(Area Under the Curve)**\n",
    "    - ROC 곡선의 아래 면적을 뜻함\n",
    "    - AUC가 클 수록 모델의 성능이 좋다는 의미\n",
    "    \n",
    "    \n",
    "- 사이킷런에서는 ROC AUC를 위한 roc_auc_score() 함수를 제공함\n",
    "\n",
    "<img src=\"./images/ROC.png\" alt=\"ROC\" style=\"zoom: 75%;\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/AUC.png\" alt=\"AUC\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**정밀도와 재현율**\n",
    "\n",
    "- **정밀도(Precision)와 재현율(Recall)은** 분자가 TP로 같고 **분모가 다름**\n",
    "    - $Precision = \\frac{TP}{TP + FP}$\n",
    "    - $Recall = \\frac{TP}{TP + FN}$\n",
    "\n",
    "\n",
    "- 알고리즘의 성능 평가를 위해 **정밀도와 재현율 모두 검사**해야 하는 이유\n",
    "    - **서로 반비례 관계**에 있으며 **파라미터 값**에 따라 **precision과 recall은 변함**\n",
    "        - 파라미터를 조절해 **검출율을 높이면(recall 증가) 오검출이 증가(precision이 감소)**\n",
    "        - 파라미터를 조절해 **오검출을 줄이면(precision 증가) 검출율이 감소(recall 감소)**\n",
    "    - 주로 **precision-recall curve**를 통해 성능을 평가함\n",
    "\n",
    "\n",
    "- **정밀도-재현율 곡선(Precision-Recall Curve)**\n",
    "    - **정밀도(Precision)에 대한 재현율(Recall)의 곡선**\n",
    "    \n",
    "<img src=\"./images/precision_recall_curve.png\" alt=\"precision_recall_curve\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **평균 정밀도(Average Precision)**\n",
    "    - **Average Precision은 인식 알고리즘의 성능을 하나의 값으로 표현한 것**\n",
    "    - **precision-recall curve의 아래쪽 면적으로 계산**됨\n",
    "    - 사이킷런에서는 평균 정밀도를 위한 average_precision_score() 함수를 제공함\n",
    "    \n",
    "<img src=\"./images/average_precision.png\" alt=\"average_precision\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **정밀도-재현율 곡선**은 **알고리즘의 성능**을 전반적으로 **판단**하기에 적합\n",
    "- **평균 정밀도**는 **서로 다른 알고리즘의 성능**을 **비교**하기에 적합"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
