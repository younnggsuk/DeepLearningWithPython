{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.1 핵심 개념 리뷰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1.1 AI를 위한 여러 방법\n",
    "\n",
    "###  인공지능, 머신러닝, 딥러닝\n",
    "\n",
    "#### 인공지능\n",
    "- **인공지능**은 인지 과정을 자동화하기 위한 모든 방법을 말함(사고의 자동화)\n",
    "\n",
    "\n",
    "#### 머신러닝\n",
    "- **머신러닝**은 훈련 데이터를 사용하여 자동으로 프로그램(**모델**)을 개발하는 AI의 하위 분야를 의미\n",
    "- 여기서 데이터를 프로그램으로 바꾸는 과정을 **학습**이라고 함\n",
    "\n",
    "\n",
    "#### 딥러닝\n",
    "- **딥러닝**은 기하학적 변환 함수들이 번갈아 가며 연속적으로 길게 연결된 모델을 말함\n",
    "    - 여기서 기하학적 변환 함수(연산)들은 **층**이라는 모듈을 구성함\n",
    "    - 전형적인 딥러닝 모델은 층을 쌓아 올린 형태 (층의 그래프라고 함)\n",
    "\n",
    "\n",
    "- 층은 훈련하는 동안 학습되는 **가중치** 파라미터를 가지며 여기에 모델의 지식이 저장됨\n",
    "\n",
    "- 따라서 학습 과정은 좋은 가중치 값을 찾는 것을 말함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1.2 머신러닝 분야에서 딥러닝이 특별한 이유\n",
    "\n",
    "- 불과 몇 년 만에 딥러닝은 역사적으로 컴퓨터에서 매우 어렵다고 인식된 다양한 종류의 문제에서 큰 성과를 거두었음\n",
    "    - 특히 이미지, 비디오, 사운드 등에서 유용한 정보를 추출하는 기계 인지 분야(machine perception) 분야에서 큰 성과를 거둠\n",
    "    \n",
    "    \n",
    "- 딥러닝은 많은 IT 기업에 엄청난 비즈니스 가치를 제공하고 있음\n",
    "    - 사람 수준의 음성 인식, 이미지 분류, 스마트 비서, 기계 번역 등\n",
    "\n",
    "\n",
    "- 인터넷과 같이 우리 경제와 삶을 바꿀 중요한 혁명이 될 것임(저자의 생각)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1.3 딥러닝에 대하여\n",
    "\n",
    "### 딥러닝\n",
    "\n",
    "- 딥러닝은 매우 단순함\n",
    "- 경사 하강법으로 충분히 큰 모수 모델(parametric model)을 충분히 많은 샘플에서 훈련 하기만 하면 됨\n",
    "\n",
    "\n",
    "#### 동작 방식\n",
    "- 입력과 타깃은 먼저 벡터로 바뀌어야 함\n",
    "    - 딥러닝에서 모든 것은 벡터이며 모두가 기하학적 공간에 놓인 하나의 포인트임\n",
    "\n",
    "        \n",
    "- 딥러닝 모델은 층을 연결하여 복잡한 기하학적 변환을 구성하며 이를 통해 입력 공간을 타깃 공간으로 한번에 하나의 포인트씩 매핑함\n",
    "    - 각 층은 데이터에 간단한 기하학적 변환을 수행\n",
    "    - 이러한 층들이 연결되어 복잡한 기하학적 변환을 구성\n",
    "\n",
    "#### 기하학적 변환과 미분\n",
    "\n",
    "- 기하학적 변환을 결정하는 파라미터는 층의 가중치이며 모델이 얼마나 잘 동작하는지를 기반으로 반복적으로 업데이트됨\n",
    "\n",
    "\n",
    "- 기하학적 변환의 핵심 특징은 미분이 가능해야 한다는 것\n",
    "    - 경사 하강법으로 파라미터를 학습하기 위해서 미분은 필수적임\n",
    "    - 입력에서 출력으로 바뀌는 기하학적 변환이 부드럽고 연속적이어야 함\n",
    "    \n",
    "    \n",
    "- **미분이 가능해야 한다는 점은 아주 큰 제약사항**\n",
    "\n",
    "#### 학습\n",
    "\n",
    "- 데이터가 가진 의미를 벡터와 기하학적 공간으로 변환한 후 한 공간에서 다른 공간으로 매핑하는 복잡한 기하학적 변환을 점진적으로 학습\n",
    "\n",
    "\n",
    "- 학습에 필요한 것은 원본 데이터에 있는 모든 형태의 관계를 찾기 위해 충분히 큰 고차원 공간 밖에 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1.4 핵심 기술\n",
    "\n",
    "### 딥러닝의 발전이 있을 수 있었던 요인\n",
    "\n",
    "#### 알고리즘의 혁신\n",
    "- 역전파 개발 이후 20년이 걸렸지만 2012년 이후 많은 연구자가 딥런이에 참여하면서 갈수록 더 빨라지고 있음\n",
    "\n",
    "#### 많은 양의 데이터\n",
    "- 인터넷의 성장과 무어의 법칙이 적용된 저장매체 덕분에 많은 데이터를 사용할 수 있게 되었음\n",
    "\n",
    "#### 고성능 병렬 컴퓨터 하드웨어\n",
    "- 고성능 병렬 컴퓨터 하드웨어를 값싸게 사용할 수 있게 되었음\n",
    "- 특히 NVIDIA의 GPU는 딥러닝을 위해 새롭게 디자인되었음\n",
    "\n",
    "#### 소프트웨어의 발전\n",
    "- 컴퓨팅 파워를 활용할 수 있는 다양한 소프트웨어 스택이 마련되었음\n",
    "- CUDA 라이브러리, 자동 미분을 수행하는 프레임워크(텐서플로, 케라스) 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1.5 일반적인 머신러닝 작업 흐름\n",
    "\n",
    "- 모델을 설계하고 훈련하기 전에 예측 대상, 활용 데이터, 성공 지표의 결정을 위해 문제를 이해하는 것(또한 훈련 후 제품 출시)이 정말 어려운 부분임\n",
    "\n",
    "\n",
    "### 전형적인 머신러닝 작업 흐름\n",
    "\n",
    "1. 문제를 정의\n",
    "    - 어떤 데이터?\n",
    "    - 어떤 예측 대상?\n",
    "    - 데이터는 충분한지?\n",
    "\n",
    "\n",
    "2. 목표 달성을 측정하기 위한 성공 지표 찾기\n",
    "    - 간단한 문제의 경우 정확도가 될 수 있음\n",
    "    - 특정 문제의 경우 해당 문제에 특화된 지표가 필요할 수 있음\n",
    "    \n",
    "\n",
    "3. 모델 평가를 위한 검증 과정을 준비\n",
    "    - 훈련 세트, 검증 세트, 테스트 세트 정의\n",
    "\n",
    "    \n",
    "\n",
    "4. 데이터의 벡터화 및 전처리(정규화 등)\n",
    "\n",
    "\n",
    "5. 상식 수준의 모델보다 좋은 성능을 내는 첫번째 모델을 만듦\n",
    "    - 머신러닝이 문제를 해결할 수 있는지 확인\n",
    "\n",
    "\n",
    "6. 하이퍼 파라미터 튜닝 및 regularization의 적용을 톻애 모델을 개선\n",
    "    - 검증 데이터만 사용해 조정\n",
    "    - 과대적합 시킨 후 크기를 줄이거나 regularization을 적용\n",
    "    - 하이퍼 파라미터 튜닝을 하면 검증 세트에 과대적합된다는 것을 유념하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1.6 주요 네트워크 구조\n",
    "\n",
    "### 데이터와 네트워크 구조\n",
    "\n",
    "- 네트워크 구조는 데이터 구조에 대한 가정을 담고 있음\n",
    "    - 좋은 모델을 탐색하기 위한 가설공간이 됨\n",
    "\n",
    "\n",
    "- 네트워크 구조의 가정에 데이터 구조의 가정이 잘 맞는지가 모델의 성능을 크게 좌우함\n",
    "\n",
    "\n",
    "### 여러 데이터구조에 따른 적절한 네트워크 구조 정리\n",
    "\n",
    "#### 벡터 데이터\n",
    "- 완전 연결 네트워크 (`Dense`층)\n",
    "\n",
    "\n",
    "#### 이미지 데이터\n",
    "- 2D Convnet\n",
    "\n",
    "\n",
    "#### 사운드 데이터(파형 데이터)\n",
    "- 1D Convnet(권장) 또는 RNN\n",
    "\n",
    "\n",
    "#### 텍스트 데이터\n",
    "- 1D Convnet(권장) 또는 RNN\n",
    "\n",
    "\n",
    "#### 시계열 데이터\n",
    "- RNN(권장) 또는 1D Convnet\n",
    "\n",
    "\n",
    "#### 다른 종류의 시퀀스 데이터\n",
    "- 데이터 순서에 중요한 의미(시계열 데이터 처럼)가 있다면 RNN이 나음\n",
    "- 위의 경우가 아니라면 RNN이나 1D Convnet\n",
    "\n",
    "\n",
    "#### 비디오 데이터\n",
    "- 3D Convnet(연속 동작을 감지해야 한다면)\n",
    "- 2D Convnet으로 프레임 별 특성을 추출 후 RNN이나 1D Convnet으로 시퀀스를 처리\n",
    "\n",
    "\n",
    "#### 볼륨을 가진 데이터\n",
    "- 3D Convnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전 연결 네트워크\n",
    "\n",
    "- 완전 연결 네트워크는 벡터 데이터(벡터 batch)를 처리하는 `Dense`층을 쌓은 것\n",
    "    - 한 층의 유닛이 다른 층의 모든 유닛과 연결되어 있어서 완전 연결이라고 부름\n",
    "    \n",
    "\n",
    "- 입력 특성에 특별한 가정을 두지 않는 형태\n",
    "    - 모든 입력 특성 간의 관계를 매핑함\n",
    "    \n",
    "    \n",
    "- 주로 범주형 데이터에 많이 사용되며 (다른 네트워크의 마지막 단계에서)분류나 회귀 출력을 위해서도 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전 연결 네트워크 - 이진 분류\n",
    "\n",
    "- 마지막 `Dense`층이 하나의 유닛을 가져야 하며 시그모이드 활성화 함수를 사용\n",
    "- 손실은 `binary_crossentropy`를 사용\n",
    "- 타깃은 0 또는 1이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 분류\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전 연결 네트워크 - 단일 레이블 다중 분류\n",
    "\n",
    "- 하나의 샘플이 정확히 하나의 클래스에만 속하는 문제\n",
    "- 마지막 `Dense`층이 클래스 수 만큼의 유닛을 가져야 하며 소프트맥스 활성화 함수를 사용\n",
    "- 타깃에 따른 손실\n",
    "    - 타깃이 원핫 인코딩 : `categorical_crossentropy`\n",
    "    - 타깃이 정수 숫자 : `sparse_categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 레이블 다중 분류\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전 연결 네트워크 - 다중 레이블 다중 분류\n",
    "\n",
    "- 하나의 샘플이 여러 개의 클래스에만 속할 수 있는 문제\n",
    "- 마지막 `Dense`층이 클래스 수 만큼의 유닛을 가져야 하며 시그모이드 활성화 함수를 사용\n",
    "- 손실은 `binary_crossentropy`를 사용\n",
    "- 타깃은 k-핫 인코딩이 되어야 함\n",
    "    - 원-핫 인코딩과 유사하지만 여러 개의 레이블이 1이 될 수 있음\n",
    "    - 사이킷런의 `MultiLabelBinarizer`클래스를 사용하면 쉽게 구현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 레이블 다중 분류\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전 연결 네트워크 - 회귀\n",
    "- 마지막 `Dense`층이 예측하려는 값의 수만큼의 유닛을 가져야 하며 활성화 함수는 사용하지 않음\n",
    "- 회귀에서는 여러 가지 손실을 사용할 수 있음\n",
    "    - 가장 널리 사용되는 것은 `mse`나 `mae`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_values))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convnet\n",
    "\n",
    "- 합성곱 층은 입력 텐서의 여러 위치(패치)에 동일한 기하학적 변환을 적용해 공간 방향의 지역 패턴을 찾음\n",
    "    - 이동 불변성을 가진 표현을 만들어줌\n",
    "    - 1D(시퀀스), 2D(이미지), 3D(볼륨) 등 어느 차원의 공간이라도 적용이 가능\n",
    "    \n",
    "    \n",
    "- Convnet은 일반적으로 합성곱 층과 최대 풀링 층을 쌓아서 구성함\n",
    "    - 최대 풀링 층은 downsampling과 이어지는 합성곱 층이 더 큰 부분을 볼수 있게 하는 역할\n",
    "    \n",
    "\n",
    "- Convnet의 마지막은 일반적으로 `Flatten`이나 전역 풀링 층으로 끝남\n",
    "    - 공간 특성 맵을 벡터로 변환하는 역할\n",
    "    - 뒤이어 분류나 회귀를 위한 `Dense`층이 주로 이어짐\n",
    "    \n",
    "    \n",
    "#### 깊이별 분할 합성곱\n",
    "\n",
    "- 깊이별 분할 합성곱은 일반적인 합성곱보다 더 빠르고 효율적으로 표현을 학습함\n",
    "    - 1D, 2D, 3D 모두에 해당되며 조만간 대부분(또는 완전히) 바뀔 것임\n",
    "\n",
    "\n",
    "- 새로운 네트워크를 구축할 때는 당연히 깊이별 분할 합성곱을 고려해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전형적인 이미지 분류 컨브넷 (깊이별 분할 합성곱 사용)\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.SeparableConv2D(32, 3, activation='relu',\n",
    "                                 input_shape=(height, width, channels)))\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu')\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "          \n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu')\n",
    "model.add(layers.GlobalAveragePooling2D(2))\n",
    "          \n",
    "          \n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "\n",
    "- 순환 신경망은 한번에 하나의 타임스텝씩 입력 시퀀스를 처리하고 이 과정 동안 상태를 유지함\n",
    "\n",
    "\n",
    "- RNN은 시간축을 따라 이동 불변성이 없는 패턴의 시퀀스의 경우에 적합\n",
    "    - 예를 들어 최근 데이터가 오래된 과거 데이터보다 더 중요한 시계열 데이터\n",
    "    \n",
    "    \n",
    "- 케라스에는 `SimpleRNN`, `LSTM`, `GRU`의 3가지 RNN이 있음\n",
    "    - 실전 애플리케이션에서는 `LSTM`, `GRU`를 사용해야 함\n",
    "    - `LSTM`이 더 강력하지만 비용이 많이 듦\n",
    "    - `GRU`는 더 간단하지만 비용이 적게 듦\n",
    "    \n",
    "\n",
    "- RNN의 출력\n",
    "    - 여러개의 RNN층을 겹겹이 쌓는 경우\n",
    "        - 마지막 층 이전의 모든 층은 모든 타임 스텝에 해당하는 전체 시퀀스를 출력해야 함\n",
    "        - `return_sequences=True`\n",
    "        \n",
    "    - 추가적인 RNN을 쌓지 않는 경우\n",
    "        - 전체 시퀀스 정보가 담긴 마지막 출력만 반환\n",
    "        - `return_sequences=False` (기본값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 시퀀스의 이진 분류 예 - RNN을 쌓지 않는 경우\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.LSTM(32, input_shape=(num_timesteps, num_features)))\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 시퀀스의 이진 분류 예 - RNN을 쌓는 경우\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.LSTM(32, return_sequences=True,\n",
    "                      input_shape=(num_timesteps, num_features)))\n",
    "model.add(layers.LSTM(32, return_sequences=True))\n",
    "model.add(layers.LSTM(32)\n",
    "\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1.7 딥러닝의 가능성\n",
    "\n",
    "- 기본적인 분류와 회귀 작업을 넘어서 딥러닝으로 할 수 있는 애플리케이션들은 많음\n",
    "\n",
    "\n",
    "### 입력과 출력의 종류에 따른 애플리케이션들\n",
    "\n",
    "#### 벡터 데이터를 벡터 데이터로 매핑\n",
    "- 예측 의학 : 환자의 의료 기록으로 미래 건강을 예측\n",
    "- 행동 타기팅 : 어떤 사용자를 웹사이트에 오래 머무르게 하는 웹사이트 속성을 찾기\n",
    "- 품질 제어 : 제조된 상품에서 얻은 데이터를 바탕으로 내년 제품의 불량률 예측\n",
    "\n",
    "#### 이미지 데이터를 벡터 데이터로 매핑\n",
    "- 의료 진단 보조 : 의료 영상 슬라이드를 사용해 암 진단을 예측\n",
    "- 자율 주행 자동차 : 자동차 카메라에서 촬영한 비디오 프레임 데이터를 바탕으로 휠(wheel) 각도 조정\n",
    "- 보드 게임 AI : 바둑과 체스 게임에서 상대편 말의 움직임을 예측\n",
    "- 식단 도우미 : 음식 사진을 보고 칼로리를 계산\n",
    "- 나이 예측 : 인물 사진을 보고 나이를 예측\n",
    "\n",
    "#### 시계열 데이터를 벡터 데이터로 매핑\n",
    "- 날씨 예측 : 지역별 날씨 시게열 데이터를 사용해 특정 지역의 다음 주 날씨 예측\n",
    "- 뇌-컴퓨터 인터페이스 : 뇌자도(magnetoencephalography, MEG) 시계열 데이터를 사용해 컴퓨터 명령을 실행\n",
    "- 행동 타기팅 : 사용자가 웹사이트에서 발생시킨 시계열 데이터를 사용해 제품 구매 확률을 예측\n",
    "\n",
    "#### 텍스트를 텍스트로 매핑\n",
    "- 스마트 답장 : 이메일을 보고 가능한 한줄 답변을 만듦\n",
    "- 질문 응답 : 일반적인 질문에 대한 답변을 만듦\n",
    "- 요약 : 긴 글을 짧게 요약\n",
    "\n",
    "#### 이미지를 텍스트로 매핑하기\n",
    "- 캡셔닝 : 이미지를 보고 이미지의 콘텐츠를 설명하는 짧은 캡션(caption)을 생성\n",
    "\n",
    "#### 텍스트를 이미지로 매핑하기\n",
    "- 조건부 이미지 생성 : 짧은 텍스트 설명에 부합하는 이미지를 생성\n",
    "- 로고 생성/선택 : 회사의 이름이나 설명에서 회사의 로고를 만듦\n",
    "\n",
    "#### 이미지를 이미지로 매핑하기\n",
    "- 초고해상도 변환 : 작은 크기의 이미지를 고해상도 버전으로 변환\n",
    "- 공간 깊이 감지 : 실내 이미지를 보고 공간 지도를 만듦\n",
    "\n",
    "#### 이미지와 텍스트를 텍스트로 매핑하기\n",
    "- 비주얼 QA : 이미지와 이미지 내용에 관한 자연어 질문을 보고 자연어 답변을 만듦\n",
    "\n",
    "#### 비디오와 텍스트를 텍스트로 매핑하기\n",
    "- 비디오 QA : 짧은 비디오와 비디오 내용에 관한 자연어 질문을 보고 자연어 답변을 만듦\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf_2': conda)",
   "language": "python",
   "name": "python37664bittf2condad8aea8848a2a40c78fd80e7bd19dd5cf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
